# ğŸ”§ FIX: Windows Ray Access Violation Error

## Váº¥n Ä‘á»
**Windows fatal exception: access violation** trong Ray khi cháº¡y Flower simulation.

## NguyÃªn nhÃ¢n
1. **Memory pressure**: Ray cáº§n nhiá»u memory trÃªn Windows
2. **Too many concurrent operations**: QuÃ¡ nhiá»u clients cháº¡y Ä‘á»“ng thá»i
3. **Ray bug trÃªn Windows**: Known issue vá»›i Ray trÃªn Windows

## Giáº£i phÃ¡p Ä‘Ã£ Ã¡p dá»¥ng

### 1. Giáº£m sá»‘ clients concurrent
**File:** `configs/config.yaml`
```yaml
federated:
  fraction_fit: 0.4      # Giáº£m tá»« 0.6 â†’ 0.4 (4 clients/round thay vÃ¬ 6)
  fraction_evaluate: 0.3  # Giáº£m tá»« 0.5 â†’ 0.3 (3 clients/round thay vÃ¬ 5)
  min_fit_clients: 2     # Giáº£m tá»« 3 â†’ 2
  min_evaluate_clients: 2 # Giáº£m tá»« 3 â†’ 2
```

### 2. Giáº£m batch size
**File:** `configs/config.yaml`
```yaml
training:
  batch_size: 16  # Giáº£m tá»« 32 â†’ 16 (giáº£m memory per batch)
```

### 3. Giáº£m memory per client
**File:** `src/training/federated_training_pipeline.py`
```python
client_resources = {
    "num_cpus": 1,
    "num_gpus": 0.0,
    "memory": 500 * 1024 * 1024  # 500MB per client (giáº£m tá»« default)
}
```

### 4. Set Ray environment variables
**File:** `src/training/federated_training_pipeline.py`
```python
os.environ.setdefault("RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE", "1")
os.environ.setdefault("RAY_DEDUP_LOGS", "1")
```

## Giáº£i phÃ¡p thay tháº¿ (náº¿u váº«n crash)

### Option 1: Giáº£m sá»‘ clients tá»•ng
```yaml
federated:
  num_clients: 5  # Giáº£m tá»« 10 â†’ 5
```

### Option 2: Giáº£m batch size hÆ¡n ná»¯a
```yaml
training:
  batch_size: 8  # Giáº£m tá»« 16 â†’ 8
```

### Option 3: Giáº£m local epochs
```yaml
training:
  local_epochs: 2  # Giáº£m tá»« 3 â†’ 2
```

### Option 4: DÃ¹ng threading backend (khÃ´ng dÃ¹ng Ray)
**LÆ°u Ã½:** Flower VCE yÃªu cáº§u Ray, nhÆ°ng cÃ³ thá»ƒ dÃ¹ng threading cho testing:
```python
# KhÃ´ng dÃ¹ng simulation, dÃ¹ng threading thay tháº¿
# (Cáº§n refactor code)
```

## Monitoring

Sau khi apply fixes, monitor:
1. **Memory usage**: Task Manager â†’ Memory
2. **Ray logs**: Check for memory warnings
3. **Training stability**: CÃ³ crash sau nhiá»u rounds khÃ´ng?

## Káº¿t quáº£ mong Ä‘á»£i

- âœ… Giáº£m memory pressure
- âœ… Ãt concurrent operations
- âœ… Training á»•n Ä‘á»‹nh hÆ¡n
- âš ï¸ Training cháº­m hÆ¡n (trade-off)

## Náº¿u váº«n crash

1. **Restart Ray**: `ray stop` vÃ  cháº¡y láº¡i
2. **Giáº£m num_clients**: Tá»« 10 â†’ 5
3. **Giáº£m batch_size**: Tá»« 16 â†’ 8
4. **Cháº¡y trÃªn Linux/WSL**: Ray á»•n Ä‘á»‹nh hÆ¡n trÃªn Linux

