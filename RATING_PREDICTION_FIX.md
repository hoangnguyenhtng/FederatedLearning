# âœ… FIX: Chuyá»ƒn tá»« Item Prediction â†’ Rating Prediction

## ğŸ¯ Váº¥n Ä‘á» Ä‘Ã£ phÃ¡t hiá»‡n

**NguyÃªn nhÃ¢n chÃ­nh:** Model Ä‘ang predict **item_id** (10000 classes) nhÆ°ng labels lÃ  **rating** (1-5) â†’ Mismatch nghiÃªm trá»ng!

```
âŒ SAI:
Model output: (batch, 10000) - predict item_id
Labels: (batch,) vá»›i giÃ¡ trá»‹ 1-5 - rating
â†’ CrossEntropyLoss fail hoÃ n toÃ n!
â†’ Accuracy = 0, Loss tÄƒng
```

## âœ… Giáº£i phÃ¡p: Rating Prediction (1-5)

Chuyá»ƒn sang **Rating Prediction** - Ä‘Æ¡n giáº£n hÆ¡n vÃ  phÃ¹ há»£p vá»›i dá»¯ liá»‡u.

```
âœ… ÄÃšNG:
Model output: (batch, 5) - predict rating class
Labels: (batch,) vá»›i giÃ¡ trá»‹ 0-4 (rating-1)
â†’ CrossEntropyLoss hoáº¡t Ä‘á»™ng Ä‘Ãºng!
â†’ Accuracy sáº½ tÄƒng, Loss sáº½ giáº£m
```

---

## ğŸ“ CÃ¡c file Ä‘Ã£ sá»­a

### 1. âœ… `src/data_generation/federated_dataloader.py`
**Thay Ä‘á»•i:**
- DÃ²ng 236: Äá»•i tá»« `'label': torch.tensor(item_id, ...)` 
- â†’ `'label': torch.tensor(rating - 1, ...)` (0-4)
- ThÃªm validation Ä‘á»ƒ Ä‘áº£m báº£o rating trong range [1,5]

**Code:**
```python
# Validate and convert rating to label (0-4 for 5 classes)
rating_value = int(rating)
if rating_value < 1:
    rating_value = 1
elif rating_value > 5:
    rating_value = 5
label = rating_value - 1  # Convert 1-5 â†’ 0-4

sample = {
    ...
    'rating': torch.tensor(rating, dtype=torch.long),  # Metadata (1-5)
    'label': torch.tensor(label, dtype=torch.long)  # Label for training (0-4)
}
```

---

### 2. âœ… `configs/config.yaml`
**Thay Ä‘á»•i:**
- DÃ²ng 45: `num_classes: 10000` â†’ `num_classes: 5`

**Code:**
```yaml
# Output configuration
# Rating prediction: 5 classes (ratings 1-5, mapped to 0-4)
num_classes: 5  # Changed from 10000 to 5
```

---

### 3. âœ… `src/training/federated_training_pipeline.py`
**Thay Ä‘á»•i:**
- DÃ²ng 100: `num_items = model_config.get('num_classes', 10000)` 
- â†’ `num_classes = model_config.get('num_classes', 5)`
- DÃ²ng 107: `num_items=num_items` â†’ `num_items=num_classes`

**Code:**
```python
# Rating prediction: 5 classes (ratings 1-5, mapped to 0-4)
num_classes = model_config.get('num_classes', 5)  # Changed from 10000 to 5

model = FedPerRecommender(
    ...
    num_items=num_classes,  # num_items parameter name, but value is num_classes (5)
    ...
)
```

---

### 4. âœ… `src/models/model_factory.py`
**Thay Ä‘á»•i:**
- DÃ²ng 26: `num_items = model_config.get("num_classes", 10000)` 
- â†’ `num_classes = model_config.get("num_classes", 5)`
- DÃ²ng 33: `num_items=num_items` â†’ `num_items=num_classes`

**Code:**
```python
# Rating prediction: 5 classes (ratings 1-5, mapped to 0-4)
num_classes = model_config.get("num_classes", 5)  # Changed from 10000 to 5

return FedPerRecommender(
    ...
    num_items=num_classes,  # num_items parameter name, but value is num_classes (5)
    ...
)
```

---

### 5. âœ… `src/federated/client.py`
**Thay Ä‘á»•i:**
- DÃ²ng 151: Äá»•i tá»« `batch_data.get('label', batch_data.get('item_id', ...))`
- â†’ `batch_data.get('label', batch_data['rating'] - 1)`
- ThÃªm validation: `torch.clamp(labels, 0, 4)`
- Sá»­a cáº£ `fit()` vÃ  `evaluate()`

**Code:**
```python
# Use 'label' (rating-1, range 0-4) for rating prediction task
labels = batch_data.get('label', batch_data['rating'] - 1).to(self.device)
# Ensure labels are in valid range [0, 4] for 5 classes
labels = torch.clamp(labels, 0, 4)

# Validate labels are in valid range [0, 4] for rating prediction (5 classes)
num_classes = logits.shape[1]  # Should be 5 for rating prediction
labels_clamped = torch.clamp(labels, 0, num_classes - 1)
```

---

### 6. âœ… `src/training/training_utils.py`
**Thay Ä‘á»•i:**
- DÃ²ng 244, 329: Äá»•i tá»« `targets = batch['rating'].to(device)`
- â†’ Sá»­ dá»¥ng `batch['label']` vá»›i fallback convert rating-1

**Code:**
```python
# Use 'label' (rating-1, range 0-4) for rating prediction task
# If 'label' not available, convert rating (1-5) to label (0-4)
if 'label' in batch:
    targets = batch['label'].to(device)
else:
    targets = (batch['rating'].to(device) - 1).clamp(0, 4)  # Convert 1-5 â†’ 0-4
```

---

## ğŸ¯ Káº¿t quáº£ mong Ä‘á»£i

### TrÆ°á»›c khi sá»­a:
```
Model: (batch, 10000) - predict item_id
Labels: (batch,) vá»›i giÃ¡ trá»‹ 1-5 - rating
â†’ CrossEntropyLoss: pred[item_id], target=rating â†’ SAI!
â†’ Accuracy = 0.0000
â†’ Loss tÄƒng liÃªn tá»¥c
```

### Sau khi sá»­a:
```
Model: (batch, 5) - predict rating class
Labels: (batch,) vá»›i giÃ¡ trá»‹ 0-4 (rating-1)
â†’ CrossEntropyLoss: pred[class], target=class â†’ ÄÃšNG!
â†’ Accuracy sáº½ tÄƒng dáº§n (target: 0.3-0.5 sau 50 rounds)
â†’ Loss sáº½ giáº£m dáº§n (target: < 1.0 sau 50 rounds)
```

---

## ğŸ“Š Expected Metrics

### Training Progress:
- **Round 1-10**: Loss ~2.0-3.0, Accuracy ~0.2-0.3
- **Round 11-30**: Loss ~1.0-2.0, Accuracy ~0.3-0.4
- **Round 31-50**: Loss ~0.5-1.0, Accuracy ~0.4-0.5

### Final Results (after 50 rounds):
- **Train Loss**: ~0.8-1.2
- **Test Loss**: ~1.0-1.5
- **Accuracy**: ~0.35-0.50 (35-50%)
- **Per-class accuracy**: Balanced across 5 rating classes

---

## âœ… Checklist

- [x] Dataset returns rating-1 (0-4) as label
- [x] Config set num_classes=5
- [x] Model outputs 5 classes
- [x] Training pipeline uses num_classes=5
- [x] Client validates labels in range [0,4]
- [x] Training utils uses label instead of rating

---

## ğŸš€ Next Steps

1. **Cháº¡y láº¡i training:**
   ```bash
   python src/training/federated_training_pipeline.py
   ```

2. **Monitor metrics:**
   - Accuracy should increase from 0 â†’ 0.3-0.5
   - Loss should decrease from ~2.3 â†’ ~1.0

3. **Náº¿u váº«n cÃ³ váº¥n Ä‘á»:**
   - Check logs for label range warnings
   - Verify model output shape is (batch, 5)
   - Check if labels are in range [0, 4]

---

## ğŸ“ Notes

- **Model parameter name**: Váº«n dÃ¹ng `num_items` trong `FedPerRecommender.__init__()` nhÆ°ng giÃ¡ trá»‹ lÃ  `num_classes=5`
- **Label conversion**: Rating 1-5 â†’ Label 0-4 (rating - 1)
- **Backward compatibility**: Code váº«n há»— trá»£ cáº£ `label` vÃ  `rating` (vá»›i conversion)

